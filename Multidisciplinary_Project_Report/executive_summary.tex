% A LaTeX template for EXECUTIVE SUMMARY of the MSc Thesis submissions to 
% Politecnico di Milano (PoliMi) - School of Industrial and Information Engineering
%
% S. Bonetti, A. Gruttadauria, G. Mescolini, A. Zingaro
% e-mail: template-tesi-ingind@polimi.it
%
% Last Revision: October 2021
%
% Copyright 2021 Politecnico di Milano, Italy. NC-BY

\documentclass[11pt,a4paper,twocolumn]{article}

%------------------------------------------------------------------------------
%	REQUIRED PACKAGES AND  CONFIGURATIONS
%------------------------------------------------------------------------------
% PACKAGES FOR TITLES
\usepackage{titlesec}
\usepackage{color}

% PACKAGES FOR LANGUAGE AND FONT
\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[T1]{fontenc} % Font encoding

% PACKAGES FOR IMAGES
\usepackage{graphicx}
\graphicspath{{Images/}} % Path for images' folder
\usepackage{eso-pic} % For the background picture on the title page
\usepackage{subfig} % Numbered and caption subfigures using \subfloat
\usepackage{caption} % Coloured captions
\usepackage{transparent}

% STANDARD MATH PACKAGES
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{bm}
\usepackage[overload]{empheq}  % For braced-style systems of equations

% PACKAGES FOR TABLES
\usepackage{tabularx}
\usepackage{longtable} % tables that can span several pages
\usepackage{colortbl}

% PACKAGES FOR ALGORITHMS (PSEUDO-CODE)
\usepackage{algorithm}
\usepackage{algorithmic}

% PACKAGES FOR REFERENCES & BIBLIOGRAPHY
\usepackage[colorlinks=true,linkcolor=black,anchorcolor=black,citecolor=black,filecolor=black,menucolor=black,runcolor=black,urlcolor=black]{hyperref} % Adds clickable links at references
\usepackage{cleveref}
\usepackage[square, numbers, sort&compress]{natbib} % Square brackets, citing references with numbers, citations sorted by appearance in the text and compressed
\bibliographystyle{plain} % You may use a different style adapted to your field

% PACKAGES FOR THE APPENDIX
\usepackage{appendix}

% PACKAGES FOR ITEMIZE & ENUMERATES 
\usepackage{enumitem}

% OTHER PACKAGES
\usepackage{amsthm,thmtools,xcolor} % Coloured "Theorem"
\usepackage{comment} % Comment part of code
\usepackage{fancyhdr} % Fancy headers and footers
\usepackage{lipsum} % Insert dummy text
\usepackage{tcolorbox} % Create coloured boxes (e.g. the one for the key-words)
\usepackage{stfloats} % Correct position of the tables

%-------------------------------------------------------------------------
%	NEW COMMANDS DEFINED
%-------------------------------------------------------------------------
% EXAMPLES OF NEW COMMANDS -> here you see how to define new commands
\newcommand{\bea}{\begin{eqnarray}} % Shortcut for equation arrays
\newcommand{\eea}{\end{eqnarray}}
\newcommand{\e}[1]{\times 10^{#1}}  % Powers of 10 notation
\newcommand{\mathbbm}[1]{\text{\usefont{U}{bbm}{m}{n}#1}} % From mathbbm.sty
\newcommand{\pdev}[2]{\frac{\partial#1}{\partial#2}}
% NB: you can also override some existing commands with the keyword \renewcommand

%----------------------------------------------------------------------------
%	ADD YOUR PACKAGES (be careful of package interaction)
%----------------------------------------------------------------------------


%----------------------------------------------------------------------------
%	ADD YOUR DEFINITIONS AND COMMANDS (be careful of existing commands)
%----------------------------------------------------------------------------


% Do not change Configuration_files/config.tex file unless you really know what you are doing. 
% This file ends the configuration procedures (e.g. customizing commands, definition of new commands)
\input{Configuration_files/config}

% Insert here the info that will be displayed into your Title page 
% -> title of your work
\renewcommand{\title}{4WIS4WID mobile robot autonomous navigation in agricultural setting using End-to-End Reinforcement Learning}
% -> author name and surname
\renewcommand{\author}{Paolo Ginefra}
% -> advisor name and surname
\newcommand{\advisor}{Prof. Marcello Restelli}
% IF AND ONLY IF you need to modify the co-supervisors you also have to modify the file Configuration_files/title_page.tex (ONLY where it is marked)
\newcommand{\firstcoadvisor}{Name Surname} % insert if any otherwise comment
%\newcommand{\secondcoadvisor}{Name Surname} % insert if any otherwise comment
% -> academic year
\newcommand{\YEAR}{2024-2025}

%-------------------------------------------------------------------------
%	BEGIN OF YOUR DOCUMENT
%-------------------------------------------------------------------------
\begin{document}

%-----------------------------------------------------------------------------
% TITLE PAGE
%-----------------------------------------------------------------------------
% Do not change Configuration_files/TitlePage.tex (Modify it IF AND ONLY IF you need to add or delete the Co-advisors)
% This file creates the Title Page of the document
\input{Configuration_files/title_page}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%     THESIS MAIN TEXT     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%-----------------------------------------------------------------------------
% INTRODUCTION
%-----------------------------------------------------------------------------
\section{Introduction}
\label{sec:introduction}

This project is meant to be an experiment: \textbf{can task 1 of the Field Robot Event 25 be solved using RockerBot with an End-to-End Reinforcement Learning approach?} 

Secondly, this was the author's first real-world application of the reinforcement learning framework, and thus, gaining insight into the process itself was another major objective, beyond simply completing the task. This is reflected in the numerous mistakes made during development, which are mostly summarised in [].

Lastly, this project is still far from its original goal due to major unforeseen technical challenges that consumed a big portion of the time budget. Despite this, 

\section{The Task}
\label{sec:task}

\subsection{Field Robot Event 2025}
The Field Robot Event (FRE) is an international competition where university teams design, build, and test autonomous agricultural robots. The event challenges the robots to perform realistic farming tasks such as navigating crop rows, recognising plants and obstacles, detecting weeds, and mapping fields. It aims to promote innovation in agricultural robotics by providing students with practical experience in robotics, AI, and engineering applied to sustainable farming. The competition includes several tasks testing precision, navigation, object recognition, and a freestyle challenge showcasing novel capabilities.
To make the competition more challenging, each robot \textbf{cannot use any form of satellite-based positioning (GPS, ...)}.
The 2025 edition was held in Milan, Italy, running from June 9 to 12.

\subsection{FRE25 Task 1 - Autonomous Navigation}
\label{subsec:task1}
Among the 5 tasks of the competition, the first has been selected as the most suitable to be solved with Reinforcement Learning. That is because it is both the least structured one (other tasks involve object recognition and some form of counting) and the one more closely related to control (something in which RL typically excels).

The Task takes place in a cultivated field, among rows of small corn plants, each with a height of approximately 40/45 cm. Each row is approximately 20 m long, and it is about 75 cm apart from the others. The rows are slightly curved, but they all have roughly the same shape. The plants are evenly spaced along the rows, but sometimes they can be missing.

The robot starts in one of the corners of the field, and it needs to navigate the rows alternating between going forward and backwards. At the beginning of the task, a sequence of instructions is provided to the robot. Each instruction $i \in S_{com} = \{1,2\} \times \{L, R\}$ is a tuple that express what to do at the end of a row. It specifies how many rows to skip and the direction of the turn. The direction assumes that the robot faces the end of the row. The sequence of instructions $I \in \bigcup_{i=1}^{\infty}S_{com}^i$ has no specified length. The layout of the task can be found displayed in Figure \ref{fig:task1}.

\begin{figure}
    \centering
    \includegraphics[width=\linewidth]{Multidisciplinary_Project_Report//Images/Task1Schema.png}
    \caption{A diagram displaying the configuration of Task 1}
    \label{fig:task1}
\end{figure}

\subsection{Rockerbot}
\label{sec:rockerbot}

The robot developed by Politecnico di Milano for the Field Robot Event is called Rockerbot. It was upgraded to its current form for the 2024 edition, and it remained mostly unchanged for the 2025 one. A picture of Rockerbot in the crop field of Task 1 of the FRE24 can be found in Figure \ref{fig:rockerbot}.

Rockerbot is a mobile robot with 4 driving wheels. What makes this robot unique is the fact that each wheel can rotate on its zenithal axis, and each yaw can be controlled independently. This gives rise to the \textbf{4 Wheels Independent Steering 4 Wheels Independent Drive (4WIS4WID) kinematic \cite{4WIS4WID}}.

Rockerbot is equipped with two encoders per wheel: a position encoder for the yaw and a velocity encoder for the angular velocity along the spinning axis. Furthermore, it features two planar LIDARs, one located at the front and one at the rear, with the plane of perception parallel to the ground. The encoders and the LIDARs are the only means of perception available.

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Multidisciplinary_Project_Report/Images/Rockerbot.png}
    \caption{A photo of Rockerbot in the field of Task 1 of the FRE 24}
    \label{fig:rockerbot}
\end{figure}

\section{The 4WIS4WID kinematic}

\begin{figure}
    \centering
    \includegraphics[width=1\linewidth]{Multidisciplinary_Project_Report/Images/4WISskematic.png}
    \caption{The schematic of the 4WIS4WID kinematic taken from \cite{4WISschematic}}
    \label{fig:4WIS}
\end{figure}

This peculiar kinematic is really flexible, and it theoretically allows the robot to achieve all 3 of its planar degrees of freedom. All the following notation is depicted in Figure \ref{fig:4WIS} and it is in line with \cite{4WIS4WID} and \cite{4WISschematic}.

The robot coordinate frame $\{X_A, Y_A\}$ is attached to the robot's center of mass (CoM), which moves with a linear velocity $\mathbf{v}_A = [v_{xA}, v_{yA}]^T$ and an angular velocity $\omega_A$. 
Each wheel $i \in \{1, 2, 3, 4\}$ has a steering angle $\delta_i$ and linear velocity $\vec{v}_i = [v_{xi}, v_{yi}]^T$ expressed in the vehicle frame. 
The front and rear axles are separated by a wheelbase of $L_f + L_r$, while the track width is $W$. 
The world coordinate frame $\{X_W, Y_W\}$ is fixed to the ground, and $\theta_A$ denotes the vehicle's heading angle with respect to the global $X_W$ axis. 
The front wheels (1, 2) and rear wheels (3, 4) can each steer independently, allowing omnidirectional motion.

Unfortunately, Rockerbot imposes some constraints:
\begin{itemize}
    \item Due to cable management, each wheel can only rotate 180°: 
    $$
    -\pi/2 \leq \delta_i \leq \pi/2 \quad \forall i \in \{1, \cdots, 4\}
    $$
    \item Due to physical limitations of the motors, each wheel can reach a limited velocity and a limited zenithal angular velocity:
    $$
    |\vec{v}_i| \leq v_{max} \quad \forall i \in \{1, \cdots, 4\}
    $$
    $$
    \dot{\delta}_i \leq \dot{\delta}_{max} \quad \forall i \in \{1, \cdots, 4\}
    $$
\end{itemize}

These constraints, especially the first one, heavily restrict the feasible trajectories in the $C = \{[v_{xA}, v_{yA}, \omega_A]^T|v_{xA}, v_{yA}, \omega_A \in \mathbb{R}\}$ control space because they introduce many discontinuities.

Controlling the robot in the $C$ space will be referred to as \textbf{Full Rigid Body Kinematic (FRBK)}. That's because it harnesses all the degrees of freedom left after a rigid body assumption.

A 4WIS4WID robot control can be further constrained to obtain many more kinematics:
\begin{itemize}
    \item \textbf{Double Ackermann (2DoF)} - the robot must always be oriented as its velocity vector:
    $$
    v_{yA} = 0
    $$

    \item \textbf{Crab (2DoF)} - the robot can only translate:
    $$
    \omega_{A} = 0
    $$

    \item \textbf{Pivot (1DoF)} - the robot can only rotate in place:
    $$
    v_{xA} = v_{yA} = 0
    $$
\end{itemize}

A partial order $\leq$ between kinematics can be constructed as follows:

Let $A$ and $B$ be two kinematics, than $A \leq B$ i.f.f. all the robot's poses $[x_a, y_a, \theta_a, \delta_1, v_1, \cdots, \delta_4,v_4]^T$ reachable using $A$ can be reached using $B$. A diagram showing how the kinematics are ordered can be found in Figure \ref{fig:poset}.

\begin{figure*}
    \centering
    \includegraphics[width=1\linewidth]{Multidisciplinary_Project_Report/Images/poset.png}
    \caption{A diagram showing the "$\leq$" ordering of kinematics. If two kinematics $A$ and $B$ are connected by an arrow pointing at $B$, then $B \leq A$"}
    \label{fig:poset}
\end{figure*}

\section{Traditional Solution}
FRE's Task 1 is typically addressed using a more traditional approach, following the Sense Plan Act paradigm. of Probabilistic Robotics. More in detail, one can follow 2 strategies:
\begin{itemize}
    \item \textbf{SLAM based}: Using Simultaneous Localisation and Mapping algorithms \cite{DurrantWhyte2006SimultaneousLA} \cite{ProbabilisticRobotics}, one can use the standard navigation pipeline similar to the one implemented in the ROS package Nav2 \cite{nav2}.
    \item \textbf{SLAMless}: due to hardware limitations, SLAM might not be feasible. In that case, new, simpler custom solutions must be implemented. This was the route taken by the Politecnico's team for both FRE24 and FRE25. The solution splits the problem into three parts. \textbf{In row Navigation} is performed by extracting the relative row direction from the LIDAR scans using Computer Vision techniques, which is then followed by a PID controller. \textbf{End of Row Detection} is based on counting heuristics, while the \textbf{Turning} is performed in open-loop, counting the skipped rows using heuristics. 
\end{itemize}

\section{Project Plan}
The ultimate goal of this project is to determine how close to a competition-ready solution can be achieved using End-to-End Reinforcement Learning. This means that the agent has to be responsible for the totality of the strategy, taking only the sensor's readings as input and directly outputting the controls. If one's goal was to achieve the best competition performance in the least amount of engineering time, an end-to-end approach wouldn't be advisable. Adding inductive bias by integrating already developed solutions (like the row direction extractor of the previous approaches) would massively speed up training and allow for finer developer control.
Another alternative could have been to develop a solution by collecting human demonstrations directly in the field and train a policy using imitation learning \cite{ImitationLearning}. 

The ambitious goal of this project could not be tackled all at once; thus, it has been partitioned into the following subgoals:
\begin{enumerate}
    \item Building a simulation of FRE25 task 1
    \item Develop an RL policy in simulation
    \item Address the Sim2Real gap and deploy the policy on Rockerbot
\end{enumerate}

The very nature of this project could not allow for a linear progression between stages, since the experience and requirements of a future phase inevitably call for modification in a previous one. Unfortunately, due to time constraints, \textbf{this project could not reach the third phase}, and it stopped in the middle of the second one.

\section{Simulation}
\subsection{Simulator choice}
For the simulation, Nvidia's Isaac Lab \cite{IsaacLab} has been chosen.
Isaac Lab is an open-source framework for robotics research that leverages GPU acceleration through its foundation on NVIDIA Isaac Sim. The framework addresses common challenges in robotics research by providing a unified platform for diverse methodologies, including reinforcement learning, imitation learning, and motion planning. Its simulation capabilities utilise PhysX for physics computation and ray-tracing technologies for sensor modelling, aiming to reduce the gap between simulated and real-world robot behaviour. The framework's architecture emphasises modularity and extensibility, including pre-configured robot models and experimental environments that can be adapted to various research needs. Isaac Lab supports integration with multiple learning frameworks and can be deployed across different computational infrastructures, from local workstations to distributed cloud systems.
Isaac Lab is a powerful tool, but it is still in its developmental stage. This meant that it cannot yet accommodate a large variety of needs. Even though the final performance of the simulation is outstanding, reaching peaks of around \textbf{3000 simulation steps per second}, the development of the simulation consumed around 2/3 of the total time budget.

\subsection{Simulation Landscape}
The simulation has been developed starting from the actual CAD model of Rockerbot. Each wheel is equipped with its own couple of controllers that follow a mass-spring-damper model. The target yaw and rotational effort can be set for each wheel independently.

The ground is currently modelled by a rigid plane, and each plant is represented by a 3D model.

The strength of Isaac Lab lies in its ability to simulate many environments in parallel. In the simulation, there are $N_e$ environment. Each environment has one robot and $p = r \cdot \rho$ plants, where $r$ is the number of rows and $\rho$ is the number of plants per row.

\subsection{Row generation}
The shape of the rows is determined by a stochastic process
\[
S(t, \Theta_s): [0,1] \to \mathbb{R}^2,
\]
whose realizations define continuous curves in the plane.

In the \( i \)-th environment, at the beginning of each episode, 
the parameters \( \theta_{si} \) are sampled. 
The corresponding curve \( S(t, \theta_{si}) \) describes 
all the rows of the \( i \)-th environment for that episode.

The position of the \( j \)-th plant in the \( k \)-th row,
expressed in the environment reference frame, is given by:
\begin{align*}
    t_{ijk} &= \tfrac{j-1}{\rho-1}, \\
    \varepsilon &\sim \mathcal{N}(\vec{0}, I\sigma_p), \nonumber\\
    Plant_{ijk} &= S(t_{ijk}, \theta_{si}) + [0, k \Delta_r] + \varepsilon, \nonumber
\end{align*}
with \( i \in \{1,\!\dots,\!N_e\} \), 
\( j \in \{1,\!\dots,\!\rho\} \),
\( k \in \{1,\!\dots,\!r\} \),
and \( \Delta_r \in \mathbb{R}^+ \) the distance between rows.

In the simulator, \( S \) is implemented by interpolating a set of 
points with a cubic spline~\cite{Spline}. 
The control points are the parameters of the process. 
Let \( l_r \) be the row length and \( c_r \in \mathbb{N} \) 
the number of control points:
\begin{align*}
    \Theta &= \big((0, Y_1),\, 
        (l_r \tfrac{1}{c_r-1}, Y_2),\, \dots,\,
        (l_r, Y_{c_r})\big), \nonumber\\
    \vec{Y} &\sim \mathcal{N}(\vec{0}, I\sigma_c), \nonumber\\
\end{align*}
then 
$$
S(t, \Theta) = \text{spline}(t, \Theta)
$$

This implementation choice has been made for simplicity's sake, but future versions might implement Gaussian Processes for finer control on the rows' shape.

\subsection{Command Buffer}
The task requires the robot to follow certain commands as explained in Section \ref{subsec:task1}. In the i-th environment, at the beginning of each episode, the instruction sequence $I_i$ of fixed length $l_c \in \mathbb{N}$ is generated randomly and uniformly, and it is stored in a queue $Q(q):\{0,1\} \to S_{com}$. The queue always returns the current command and moves to the next every rising front of its control signal $q$. When the queue has reached its last command, it ignores the control.

\subsection{Waypoints}
The simulation has a waypoint system that traces the path the robot should follow. In the i-th environment, after the path parameters, $\theta_{si}$ are sampled and the command sequence $I_i$ is generated, the waypoints are set up to have $\rho_w$ evenly spaced waypoints in the middle of the relevant rows and one waypoint per row skipped during turns. The in-row waypoints start and end slightly outside the rows on the x direction by a padding of $p_{in}$. The turning waypoints have the same y coordinate as the last plant on the relevant side of the row and an x that is $p_{t}$ away in the relevant direction. The waypoints are arranged in a snake-like pattern.
The waypoints are ordered, and they can only be reached in the right sequence. For a waypoint to be reached, the robot must be at a distance of less than $\varepsilon_w$ and it must be the first unreached waypoint of the order. The only reachable waypoint at a time will be referenced as the next waypoint.

\subsection{LIDARs}
Isaac Lab has integrated simulated LIDARs based on the ray tracing capabilities of Nvidia's GPUs. Unfortunately, in the current version 
of Isaac Lab, this feature is available only for sensing static objects. Since the plants need to change position at each environment reset, they are intrinsically dynamic. This was one of the major setbacks of the project because it required a \textbf{from-scratch implementation of planar LIDARs}. Early attempts at ray tracing showed unsatisfactory performance, which led to the usage of ray marching techniques \cite{Raymarching}. This algorithm allows to find the point of intersection of a ray and a shape very efficiently.  In 2D Raymarching, shapes are described by a Signed Distance Field $sdf(\vec{x}):\mathbb{R}^2\to\mathbb{R}$ that describes the signed distance of a generic point $\vec{x} \in \mathbb{R}^2$, where a negative distance means that $\vec{x}$ is inside the shape. These functions are then used in the collision finding algorithm, as given a scene described by $\{sdf_i|i\in{1, \cdots, k}\}$ and any point $\vec{\hat{x}}$ which is outside all the shapes, surely all the points in $A_{\vec{\hat{x}}} = \{\vec{x}\in\mathbb{R}^2: ||\vec{\hat{x}}-\vec{x}||_2 \leq \min_{i}sdf_i(\vec{\hat{x}}) \}$ will be outside all the shapes. Given a ray described by a direction $\vec{d}\in\mathbb{R}^2, ||\vec{d}||_2 = 1$, and a starting point $\vec{x}^{(0)} \in \mathbb{R}^2$, the algorithm keep iterating $\vec{x}^{(n)} = \vec{x}^{(n-1)} + \vec{d} \min_{i}sdf_i(\vec{x}^{(n-1)})$ until either the maximum number of iterations $n_{lidar}$ is reached or $\min_{i}sdf_i(\vec{x}^{(n)})<\varepsilon_{lidar}$. This procedure can be used to simulate a LIDAR by simply repeating the procedure for each ray, and since each ray is independent, this can easily be parallelised. For the plants, a simple circular signed distance function has been implemented, where given a plant position $\vec{p} \in \mathbb{R}^2$ and a plant radius $r_{plant} \in \mathbb{R}^+$, $sdf_p(\vec{x})=||\vec{x} - \vec{p} ||_2 - r_{plant}$. This model is quite simplistic, but with the required smoothing and anomaly detection can be quite faithful to the actual Rockerbot's LIDARs. Another approximation is that in the simulation, the robot has only one 360° unobstructed LIDAR instead of the two of the actual robot, but once again, with the due pre-processing, the simulated configuration can be a faithful approximation.

\subsection{Termination Conditions}
For each environment, the episode terminates when at least one of the following conditions is met:
\begin{itemize}
    \item \textbf{Plant collision}: the robot collides with a plant
    \item \textbf{Out of bound}: the distance between the robot and the next waypoint is greater than the waypoint reached tolerance $\varepsilon_w$ plus the distance between the next and the last (meaning the one before the next) waypoint.
    \item \textbf{Time out}: the episode has exhusted the time budget $t_{sim}$
    \item \textbf{Completion}: The robot has reached all the waypoints
\end{itemize}


\section{Reinforcement Learning Problem Formulation}

\section{Reinforcement Learning Proposed Solution}


\section{Results}

\section{Conclusion}

\section{Guidelines}
\label{sec:guidelines}

The Executive Summary is a critical overview of your thesis
with a focus on the main achievements that have emerged from your research.

The Executive Summary should be organized in sections/paragraphs
in order to better highlight the major points of your work.
The length should range from four to six pages depending on the length of the thesis manuscript.
Keep the Executive Summary concise enough to be effective but long enough to allow it to be complete.
It should be written after completing the thesis manuscript as a stand-alone independent document
of sufficient clarity and detail to ensure that the reader can figure out the overall objectives,
the methodology employed and the results/impact of your research.

In writing the Executive Summary, keep in mind that it is not an abstract, it is not a preface,
and it is not a random collection of highlights.
With a few exceptions, do not simply cut and paste whole sections or paragraphs of the thesis manuscript
into a disorganized and cluttered Executive Summary.
You should reorganize information to be informative as well as concise.

The Executive Summary could contain a few important equations related to your work.
It could also include the most relevant figures and tables taken or elaborated from the thesis manuscript.

You should also include in the Executive Summary the very essential bibliography of your study.
The number of selected references should range from three to five depending on the type of work.

The Executive Summary should contain a final section reporting the main conclusions drawn from your research.

\section{Sections and subsections}
\label{sec:sec_and_subsec}
It is convenient to organize the Executive Summary of your thesis into sections and subsections. 
If necessary, subsubsections, paragraphs and subparagraphs can be also used. 
A new section or subsection can be included  with the commands
\begin{verbatim}
\section{Title of the section}
\end{verbatim}
\begin{verbatim}
\subsection{Title of the subsection}
\end{verbatim}
It is recommended to give a label to each section by using the command
\begin{verbatim}
\label{sec:section_name}%
\end{verbatim}
where the argument is just a text string that you'll use to reference that part
as follows: \textit{Section~\ref{sec:sec_and_subsec} contains \sc{SECTIONS AND SUBSECTIONS}  \dots}.\\

%-----------------------------------------------------------------------------
% EQUATIONS AND FIGURES
%-----------------------------------------------------------------------------
\section{Equations, Figures, Tables and Algorithms}
\label{sec:equations_and_figures}
All Figures, Tables and Algorithms have to be properly referred in the text.
Equations have to be numbered only if they are referred in the text.
\subsection{Equations}
\label{sec_equations}
A few important equations related to your work might be reported in the Executive Summary. For example, the Maxwell's equations read:
\begin{subequations}
    \label{eq:maxwell}
    \begin{align}[left=\empheqlbrace]
    \nabla\cdot \bm{D} & = \rho, \label{eq:maxwell1} \\
    \nabla \times \bm{E} +  \frac{\partial \bm{B}}{\partial t} & = \bm{0}, \label{eq:maxwell2} \\
    \nabla\cdot \bm{B} & = 0, \label{eq:maxwell3} \\
    \nabla \times \bm{H} - \frac{\partial \bm{D}}{\partial t} &= \bm{J}. \label{eq:maxwell4}
    \end{align}
\end{subequations}

Equation~\eqref{eq:maxwell} is automatically labeled by \texttt{cleveref},
as well as Equation~\eqref{eq:maxwell1} and Equation~\eqref{eq:maxwell3}.
Thanks to the \verb|cleveref| package, there is no need to use \verb|\eqref|.

\subsection{Figures}
\label{sec:figures}
To include Figures in your text you can use \texttt{TikZ} for high-quality hand-made figures \cite{tikz},
or just include them with the command
\begin{verbatim}
\includegraphics[options]{filename.xxx}
\end{verbatim}
where xxx is the format (\verb|.png|, \verb|.jpg|, \verb|.eps|, \dots).
An example is shown in Figure~\ref{fig:quadtree}.
\begin{figure}[H]
    \centering
    \includegraphics[width=0.3\textwidth]{logo_polimi_scritta.eps}
    \caption{Caption of the Figure.}
    \label{fig:quadtree}
\end{figure}

\subsection{Tables}
\label{subsec:tables}

Within the environments \texttt{table} and  \texttt{tabular} you can create very fancy tables like the one shown in Table~\ref{table:example}.
\begin{table}[H]
    \caption*{\textbf{Example of Table}}
    \centering 
    \begin{tabular}{|p{3em} c c c |}
    \hline
    \rowcolor{bluePoli!40}
     & \textbf{column1} & \textbf{column2} & \textbf{column3} \T\B \\
    \hline \hline
    \textbf{row1} & 1 & 2 & 3 \T\B \\
    \textbf{row2} & $\alpha$ & $\beta$ & $\gamma$ \T\B\\
    \textbf{row3} & alpha & beta & gamma \B\\
    \hline
    \end{tabular}
    \\[10pt]
    \caption{Caption of the Table.}
    \label{table:example}
\end{table}

\subsection{Algorithms}
\label{subsec:algorithms}

Pseudo-algorithms can be written in \LaTeX{} with the \texttt{algorithm} and \texttt{algorithmic} packages.
One example follows.
\begin{algorithm}[H]
\label{alg:example}
\caption{Name of the Algorithm}
\label{alg:var}
\label{protocol1}
\begin{algorithmic}[1]
\STATE Initial instructions
\FOR{$for-condition$}
\STATE{Some instructions}
\IF{$if-condition$}
\STATE{Some other instructions}
\ENDIF
\ENDFOR
\WHILE{$while-condition$}
\STATE{Some further instructions}
\ENDWHILE
\STATE Final instructions
\end{algorithmic}
\end{algorithm} 

\section{Some further useful recommendations}

Theorems and Propositions have to be formatted as follows:
\begin{theorem}
\label{a_theorem}
Write here your theorem. 
\end{theorem}
\textit{Proof.} If useful you can report here the proof.
\vspace{0.3cm} % Insert vertical space

How to write propositions:
\begin{proposition}
Write here your proposition.
\end{proposition}
\vspace{0.3cm} % Insert vertical space

How to insert itemized lists:
\begin{itemize}
    \item first item;
    \item second item.
\end{itemize}
How to insert numbered lists:
\begin{enumerate}
    \item first item;
    \item second item.
\end{enumerate}

%-----------------------------------------------------------------------------
% HOW TO CITE BIBLIOGRAPHY
%-----------------------------------------------------------------------------
\section{Bibliography}
\label{sec:bibliography}
The Executive Summary should contain the very essential bibliography of your study.
It is suggested to use the BibTeX package \cite{bibtex} and save the bibliographic references
in the file  \verb|bibliography.bib|.

%-----------------------------------------------------------------------------
% CONCLUSION
%-----------------------------------------------------------------------------
\section{Conclusions}
A final section containing the main conclusions of your research/study have to be inserted here.

%---------------------------------------------------------------------------
%  ACKNOWLEDGEMENTS 
%---------------------------------------------------------------------------
\section{Acknowledgements}
Here you might want to acknowledge someone.

%---------------------------------------------------------------------------
%  BIBLIOGRAPHY
%---------------------------------------------------------------------------
% Remember to insert here only the essential bibliography of your work
\bibliography{bibliography.bib} % automatically inserted and ordered with this command 

\end{document}